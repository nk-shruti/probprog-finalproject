{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Predictive' from 'pyro.infer' (/Users/raksh/anaconda3/lib/python3.7/site-packages/pyro/infer/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-a3b1bbf92da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUniform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmpiricalMarginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrace_ELBO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJitTrace_ELBO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracePredictive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPredictive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoguide\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoMultivariateNormal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMCMC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Predictive' from 'pyro.infer' (/Users/raksh/anaconda3/lib/python3.7/site-packages/pyro/infer/__init__.py)"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "import torch\n",
    "# from torch.distributions import constraints\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.distributions import Normal, Uniform, Delta\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, JitTrace_ELBO, TracePredictive\n",
    "from pyro.contrib.autoguide import AutoMultivariateNormal\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "from pyro.infer.mcmc import NUTS\n",
    "from pyro.infer.mcmc.util import diagnostics\n",
    "\n",
    "import pyro.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "from pyro.ops.stats import waic\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "assert pyro.__version__.startswith('0.4.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /Users/raksh/anaconda3/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/raksh/anaconda3/lib/python3.7/site-packages (from imblearn) (0.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /Users/raksh/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.21.2)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/raksh/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /Users/raksh/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.17.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/raksh/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.20->imbalanced-learn->imblearn) (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "# Enable validation checks\n",
    "pyro.enable_validation(True)\n",
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.set_rng_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/crap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data.apply(lambda row : row['FELONY'] + row['MISDEMEANOR'] + row['VIOLATION'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, features, target):\n",
    "    df_X = data[features]\n",
    "    df_y = data[target]\n",
    "    \n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    Xus, yus = rus.fit_resample(df_X, df_y)\n",
    "    \n",
    "    print(len(Xus),len(yus))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xus, yus, test_size=0.2)\n",
    "    # Train Data\n",
    "    X_np_train = normalize(np.array(X_train))\n",
    "    y_np_train = np.array(y_train)\n",
    "    \n",
    "\n",
    "    X_nuts_train = torch.from_numpy(X_np_train).type(torch.float32)\n",
    "    y_nuts_train = torch.from_numpy(y_np_train).type(torch.float32)\n",
    "\n",
    "   \n",
    "    #Test Data\n",
    "    X_np_test = normalize(np.array(X_test))\n",
    "    y_np_test = np.array(y_test)\n",
    "    \n",
    "    print(y_np_test.sum(), len(y_np_test)-y_np_test.sum())\n",
    "\n",
    "    X_nuts_test = torch.from_numpy(X_np_test).type(torch.float32)\n",
    "    y_nuts_test = torch.from_numpy(y_np_test).type(torch.float32)\n",
    "\n",
    "#     test_population =  torch.from_numpy(np.array(X_test['TotalPop'])).type(torch.float32)\n",
    "    return X_nuts_train, y_nuts_train, population, X_nuts_test, y_nuts_test, test_population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_split = 3\n",
    "offset = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_data(row):\n",
    "    if row['target'] >= bool_split + offset :\n",
    "        return 1\n",
    "    elif row['target'] <= bool_split - offset :\n",
    "        return 0\n",
    "    else:\n",
    "        return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'month', 'CensusTract', 'TotalPop', 'Income', 'IncomeErr',\n",
       "       'IncomePerCap', 'IncomePerCapErr', 'Poverty', 'ChildPoverty',\n",
       "       'Professional', 'Service', 'Office', 'Construction', 'Production',\n",
       "       'WorkAtHome', 'MeanCommute', 'Employed', 'PrivateWork', 'PublicWork',\n",
       "       'SelfEmployed', 'FamilyWork', 'Unemployment', 'FELONY', 'MISDEMEANOR',\n",
       "       'VIOLATION', 'restaurants', 'bar', 'park', 'subway_station', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['TotalPop', 'Income', 'IncomeErr',\n",
    "       'IncomePerCap', 'IncomePerCapErr', 'Poverty', 'ChildPoverty',\n",
    "       'Professional', 'Service', 'Office', 'Construction', 'Production',\n",
    "       'WorkAtHome', 'MeanCommute', 'Employed', 'PrivateWork', 'PublicWork',\n",
    "       'SelfEmployed', 'FamilyWork', 'Unemployment','restaurants', 'bar', 'park', 'subway_station']\n",
    "target = 'binary_target'            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bool_split in range(2,10):\n",
    "#     for offset in range(1,5):\n",
    "\n",
    "bool_split = 5\n",
    "offset = 2\n",
    "\n",
    "for bool_split in range(2,20):\n",
    "    for offset in range(1,10):\n",
    "        if bool_split - offset <= 0:\n",
    "            continue\n",
    "        print(bool_split, offset)\n",
    "        data_new = deepcopy(data)\n",
    "        data_new['binary_target'] = data_new.apply(sep_data, axis=1)\n",
    "        data_new = data_new.dropna()\n",
    "#         print(len(data_new[data_new['binary_target']==0]), len(data_new[data_new['binary_target']==1]))\n",
    "        if (len(data_new[data_new['binary_target']==0]) == 0) or (len(data_new[data_new['binary_target']==1]) == 0):\n",
    "            print('-'*30)\n",
    "            continue\n",
    "        X_nuts_train, y_nuts_train, population, X_nuts_test, y_nuts_test, test_population = get_data(data_new, features, target)\n",
    "        reg = LogisticRegression(C=0.8).fit(X_nuts_train, y_nuts_train)\n",
    "        print('Train Score : ',reg.score(X_nuts_train, y_nuts_train))\n",
    "        print('Test Score :', reg.score(X_nuts_test, y_nuts_test))\n",
    "        print('-'*30)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1598 1598\n",
      "149.0 171.0\n"
     ]
    }
   ],
   "source": [
    "bool_split = 9\n",
    "offset = 5\n",
    "\n",
    "\n",
    "data_new = deepcopy(data)\n",
    "data_new['binary_target'] = data_new.apply(sep_data, axis=1)\n",
    "data_new = data_new.dropna()\n",
    "X_nuts_train, y_nuts_train, population, X_nuts_test, y_nuts_test, test_population = get_data(data_new, features, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "import torch\n",
    "# from torch.distributions import constraints\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.distributions import Normal, Uniform, Delta\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, JitTrace_ELBO, TracePredictive\n",
    "from pyro.contrib.autoguide import AutoMultivariateNormal\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "from pyro.infer.mcmc import NUTS\n",
    "from pyro.infer.mcmc.util import diagnostics\n",
    "import pyro.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from pyro.ops.stats import waic\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch.distributions import constraints\n",
    "from pyro.infer.autoguide.initialization import init_to_mean\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "assert pyro.__version__.startswith('0.4.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data_x, data_y, D):\n",
    "    beta = []\n",
    "    for i in range(D+1):\n",
    "        beta.append(pyro.sample(\"beta\"+str(i), dist.Normal(0., 100)))\n",
    "            \n",
    "    logit = beta[0]\n",
    "    for i in range(D):\n",
    "        logit = logit + beta[i+1]*data_x[:,i]\n",
    "    \n",
    "    \n",
    "    p = 1. / (1 + torch.exp(-logit))\n",
    "\n",
    "    with pyro.plate(\"data\", len(data_x)):\n",
    "        y = pyro.sample(\"obs\",dist.Bernoulli(p), obs=data_y)\n",
    "    \n",
    "    return p \n",
    "\n",
    "\n",
    "def guide(data_x, data_y, D):\n",
    "    \n",
    "    mu_i = []\n",
    "    sigma_i = []\n",
    "    for i in range(D+1):\n",
    "        mu_i.append(pyro.param('mu_i'+str(i),torch.tensor(0.),constraint = constraints.real))\n",
    "        sigma_i.append(pyro.param('sigma_i'+str(i),torch.tensor(1.), constraint = constraints.positive))\n",
    "        \n",
    "#     mu_sd_u_lower = pyro.param('mu_sd_u_lower',torch.tensor(0.),constraint = constraints.real)\n",
    "#     mu_sd_u_upper = pyro.param('mu_sd_u_upper',torch.tensor(100.),constraint = constraints.positive)\n",
    "    \n",
    "#     mu_u_i = pyro.param('mu_u_i',torch.tensor(0.),constraint = constraints.real)\n",
    "    \n",
    "    \n",
    "    beta = []\n",
    "    for i in range(D+1):\n",
    "        beta.append(pyro.sample(\"beta\"+str(i), dist.Normal(mu_i[i], sigma_i[i])))\n",
    "        \n",
    "#     sd_u = pyro.sample(\"sd_u\",dist.Uniform(mu_sd_u_lower, mu_sd_u_upper))\n",
    "\n",
    "    logit = beta[0]\n",
    "    for i in range(D):\n",
    "        logit = logit + beta[i+1]*data_x[:,i]\n",
    "    \n",
    "    \n",
    "#     sigma2_ui = 1/(sd_u**2) \n",
    "#     u_i = pyro.sample(\"u_i\",dist.Normal(mu_u_i, sigma2_ui))\n",
    "#     logit += u_i\n",
    "    \n",
    "    p = 1. / (1 + torch.exp(-logit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Elbo loss: 1017.8393585085869\n",
      "Elbo loss: 1146.6577889323235\n",
      "Elbo loss: 1273.625773012638\n",
      "Elbo loss: 1085.4851356744766\n",
      "Elbo loss: 903.9561595320702\n",
      "Elbo loss: 915.7168127894402\n",
      "Elbo loss: 937.2151150107384\n",
      "Elbo loss: 1001.1472007036209\n",
      "Elbo loss: 927.4754234552383\n",
      "Elbo loss: 996.5049903988838\n",
      "Elbo loss: 900.8946050405502\n",
      "Elbo loss: 862.5302802324295\n",
      "Elbo loss: 884.2530184388161\n",
      "Elbo loss: 868.5806066393852\n",
      "Elbo loss: 883.8483117222786\n",
      "Elbo loss: 882.0793562531471\n",
      "Elbo loss: 849.2443605065346\n",
      "Elbo loss: 846.2166477441788\n",
      "Elbo loss: 812.1207805871964\n",
      "Elbo loss: 812.6238313019276\n",
      "Elbo loss: 791.1523022055626\n",
      "Elbo loss: 770.9903781414032\n",
      "Elbo loss: 788.0937814116478\n",
      "Elbo loss: 749.376221626997\n",
      "Elbo loss: 781.5419896841049\n",
      "Elbo loss: 767.0750800967216\n",
      "Elbo loss: 781.1891438364983\n",
      "Elbo loss: 773.4880146980286\n",
      "Elbo loss: 740.1199125647545\n",
      "Elbo loss: 772.5911191701889\n",
      "Elbo loss: 737.6904004216194\n",
      "Elbo loss: 751.262405872345\n",
      "Elbo loss: 765.7813155651093\n",
      "Elbo loss: 733.7054207324982\n",
      "Elbo loss: 728.8897726535797\n",
      "Elbo loss: 715.6042494177818\n",
      "Elbo loss: 718.2049401402473\n",
      "Elbo loss: 716.2902337312698\n",
      "Elbo loss: 700.5200774073601\n",
      "Elbo loss: 710.2559123635292\n",
      "Elbo loss: 695.2685695886612\n",
      "Elbo loss: 686.1624689102173\n",
      "Elbo loss: 697.9460835456848\n",
      "Elbo loss: 698.8007704019547\n",
      "Elbo loss: 685.7577294111252\n",
      "Elbo loss: 692.5892959237099\n",
      "Elbo loss: 695.043547809124\n",
      "Elbo loss: 693.0079478621483\n",
      "Elbo loss: 681.6616251468658\n",
      "Elbo loss: 682.7298681139946\n",
      "Elbo loss: 697.7009211778641\n",
      "Elbo loss: 689.1690149307251\n",
      "Elbo loss: 686.688353896141\n",
      "Elbo loss: 692.8328189253807\n",
      "Elbo loss: 677.7897309064865\n",
      "Elbo loss: 684.6899556517601\n",
      "Elbo loss: 680.5761675834656\n",
      "Elbo loss: 676.0469869971275\n",
      "Elbo loss: 666.314212501049\n",
      "Elbo loss: 680.9045739769936\n",
      "Elbo loss: 665.883926987648\n",
      "Elbo loss: 684.8934628367424\n",
      "Elbo loss: 664.6652058959007\n",
      "Elbo loss: 672.5054211318493\n",
      "Elbo loss: 675.2036962509155\n",
      "Elbo loss: 662.9198316931725\n",
      "Elbo loss: 668.8554630279541\n",
      "Elbo loss: 669.4657102823257\n",
      "Elbo loss: 672.9250667095184\n",
      "Elbo loss: 678.2120577096939\n",
      "Elbo loss: 670.6376614868641\n",
      "Elbo loss: 672.561820089817\n",
      "Elbo loss: 661.4946807026863\n",
      "Elbo loss: 666.621710985899\n",
      "Elbo loss: 669.4145486354828\n",
      "Elbo loss: 670.1614510416985\n",
      "Elbo loss: 656.1515198349953\n",
      "Elbo loss: 655.0443452596664\n",
      "Elbo loss: 673.7984986305237\n",
      "Elbo loss: 675.7614021897316\n",
      "Elbo loss: 670.0213697552681\n",
      "Elbo loss: 666.1352555155754\n",
      "Elbo loss: 661.8432837128639\n",
      "Elbo loss: 663.6963938474655\n",
      "Elbo loss: 701.1114844083786\n",
      "Elbo loss: 665.498227596283\n",
      "Elbo loss: 661.4609586596489\n",
      "Elbo loss: 659.5106375813484\n",
      "Elbo loss: 656.521878182888\n",
      "Elbo loss: 655.4846673607826\n",
      "Elbo loss: 660.8737610578537\n",
      "Elbo loss: 659.5202268362045\n",
      "Elbo loss: 667.3029447793961\n",
      "Elbo loss: 662.0729093551636\n",
      "Elbo loss: 662.6393513083458\n",
      "Elbo loss: 663.2070161104202\n",
      "Elbo loss: 657.9883350133896\n",
      "Elbo loss: 662.7163000106812\n",
      "Elbo loss: 679.6840918660164\n",
      "Elbo loss: 655.5200857520103\n",
      "Elbo loss: 654.765222787857\n",
      "Elbo loss: 666.2440733909607\n",
      "Elbo loss: 659.2171007394791\n",
      "Elbo loss: 668.7175939083099\n",
      "Elbo loss: 652.7138497829437\n",
      "Elbo loss: 654.4220590591431\n",
      "Elbo loss: 653.587362408638\n",
      "Elbo loss: 664.3870273828506\n",
      "Elbo loss: 667.3266170620918\n",
      "Elbo loss: 657.8018277287483\n",
      "Elbo loss: 652.7680043578148\n",
      "Elbo loss: 648.0480319857597\n",
      "Elbo loss: 657.6587827801704\n",
      "Elbo loss: 655.0472185015678\n",
      "Elbo loss: 667.2731021046638\n",
      "Elbo loss: 663.3616113066673\n",
      "Elbo loss: 654.2596184015274\n",
      "Elbo loss: 667.9958528280258\n",
      "Elbo loss: 652.9891564846039\n",
      "Elbo loss: 660.4339477419853\n",
      "Elbo loss: 661.5320994853973\n",
      "Elbo loss: 663.160567343235\n",
      "Elbo loss: 660.5305185317993\n",
      "Elbo loss: 692.2211102247238\n",
      "Elbo loss: 658.393689095974\n",
      "Elbo loss: 660.9959780573845\n",
      "Elbo loss: 653.4738299250603\n",
      "Elbo loss: 652.7588853240013\n",
      "Elbo loss: 651.2197933495045\n",
      "Elbo loss: 669.6687164306641\n",
      "Elbo loss: 663.2023341059685\n",
      "Elbo loss: 649.3956437110901\n",
      "Elbo loss: 666.1880339384079\n",
      "Elbo loss: 654.7265731692314\n",
      "Elbo loss: 660.9495362639427\n",
      "Elbo loss: 649.1342002749443\n",
      "Elbo loss: 658.8216600418091\n",
      "Elbo loss: 683.3962324261665\n",
      "Elbo loss: 648.3007228970528\n",
      "Elbo loss: 666.7477999925613\n",
      "Elbo loss: 649.7682952284813\n",
      "Elbo loss: 664.3008229136467\n",
      "Elbo loss: 655.5187803506851\n",
      "Elbo loss: 653.5405524373055\n",
      "Elbo loss: 650.0114893913269\n",
      "Elbo loss: 656.195629298687\n",
      "Elbo loss: 651.871744632721\n",
      "Elbo loss: 653.7014862895012\n",
      "Elbo loss: 653.2988702058792\n",
      "Elbo loss: 656.5591645240784\n",
      "Elbo loss: 686.8865125179291\n",
      "Elbo loss: 645.893176317215\n",
      "Elbo loss: 656.4847011566162\n",
      "Elbo loss: 663.0590093135834\n",
      "Elbo loss: 648.9299756884575\n",
      "Elbo loss: 663.1250602006912\n",
      "Elbo loss: 662.7063724398613\n",
      "Elbo loss: 659.7699964642525\n",
      "Elbo loss: 658.0226294994354\n",
      "Elbo loss: 661.1544153094292\n",
      "Elbo loss: 648.285679936409\n",
      "Elbo loss: 662.6448751091957\n",
      "Elbo loss: 654.673664689064\n",
      "Elbo loss: 654.9795275330544\n",
      "Elbo loss: 653.6622951030731\n",
      "Elbo loss: 655.2001540064812\n",
      "Elbo loss: 657.7799381017685\n",
      "Elbo loss: 657.467694580555\n",
      "Elbo loss: 654.3296350240707\n",
      "Elbo loss: 659.4352331161499\n",
      "Elbo loss: 659.4423751235008\n",
      "Elbo loss: 650.0647847056389\n",
      "Elbo loss: 651.207392334938\n",
      "Elbo loss: 669.9419827461243\n",
      "Elbo loss: 673.710109770298\n",
      "Elbo loss: 651.1489228010178\n",
      "Elbo loss: 651.3133195638657\n",
      "Elbo loss: 658.488339394331\n",
      "Elbo loss: 645.0229845046997\n",
      "Elbo loss: 643.1997789740562\n",
      "Elbo loss: 662.8792538642883\n",
      "Elbo loss: 651.2671650052071\n",
      "Elbo loss: 656.0771511793137\n",
      "Elbo loss: 665.7506827116013\n",
      "Elbo loss: 655.4463824033737\n",
      "Elbo loss: 657.3914884924889\n",
      "Elbo loss: 650.8544708490372\n",
      "Elbo loss: 660.1690569519997\n",
      "Elbo loss: 654.4861568808556\n",
      "Elbo loss: 645.4436802864075\n",
      "Elbo loss: 653.8084354996681\n",
      "Elbo loss: 658.1377038955688\n",
      "Elbo loss: 655.8851259946823\n",
      "Elbo loss: 663.7641599178314\n",
      "Elbo loss: 645.8475670218468\n",
      "Elbo loss: 660.811551451683\n",
      "Elbo loss: 654.1453093290329\n",
      "Elbo loss: 655.4430173635483\n",
      "Elbo loss: 657.5588665008545\n",
      "Elbo loss: 648.3496134281158\n"
     ]
    }
   ],
   "source": [
    "svi = SVI(model, \n",
    "          guide, \n",
    "          optim.Adam({\"lr\": .0005}), \n",
    "          loss=Trace_ELBO(), \n",
    "          num_samples=20000)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "elbo_arr = []\n",
    "for i in range(100000):\n",
    "    elbo = svi.step(X_nuts_train, y_nuts_train, X_nuts_train.shape[1])\n",
    "    elbo_arr.append(elbo)\n",
    "    if i % 500 == 0:\n",
    "        logging.info(\"Elbo loss: {}\".format(elbo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x139a32a90>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(elbo_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    model_preds = []\n",
    "    for i in range(len(x)):\n",
    "        guide_trace = pyro.poutine.trace(guide).get_trace(x,None,x.shape[1])\n",
    "        replay_result = pyro.poutine.replay(model, guide_trace)(x,None,x.shape[1])\n",
    "        model_preds.append(replay_result.detach().numpy())\n",
    "    return model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "ypred = predict(X_nuts_test)\n",
    "# accuracy_score(ypred, y_nuts_test)\n",
    "print(len(ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320,)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(320):\n",
    "    preds.append(1 if ypred[i][i]>=0.5 else 0)\n",
    "acc = accuracy_score(preds,y_nuts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
